>>> acquisizione file
	- copiato file GNN.py
	- copiato file GNN_BaseClass.py
	- copiato file graph_claass.py

>>> tolta classe GNN2:
	- rimossa dichiarazione classe GNN2

>>> cambiati nomi classi
	- cambiato nome file GNN_BaseClass.py -> CGNN_BaseClass.py
	- cambiato nome file GNN.py -> CGNN.py
	- cambiato nome file graph_class.py -> composite_graph_class.py
	- cambiato nome classe BaseGNN -> BaseCGNN
	- cambiato nome classe GNNnodeBased -> CGNNnodeBased
	- cambiato nome classe GNNgraphBased -> CGNNgraphBased
	- cambiato nome classe GNNedgeBased -> CGNNedgeBased
	- cambiato nome classe GraphObject -> CompositeGraphObject

>>> tolta modalità con state_vector inizializzato con i label:
	- in CGNNnodeBased.__init__() cambiato controllo state_vector_dim da maggiore/uguale a 0 a maggiore stretto
	- in CGNNnodeBased.Loop() tolta condizione state_vector_dim > 0 per inizializzazione stato
	- in CGNNnodeBased.Loop() tolta inizializzazione con labels quando state_vector_dim == 0
	- in CGNNnodeBased.convergence() tolta concatenazione label nodo partenza a messaggio arco
	- in CGNNnodeBased.convergence() tolta condizione "if state_vector_dim:" a concatenazione input stato

>>> inizializzazione state vector randomizzata:
	- in CGNNnodeBased.__init__() inserito nuovo parametro state_init_stdev
	- in CGNNnodeBased.__init__() aggiunta costruzione self.state_init_stdev
	- in CGNNnodeBased.__init__() aggiunto controllo state_init_stdev >= 0.0
	- in CGNNnodeBased.Loop() cambiata inzializzazione state_old da tf.ones_like() a tf.random.normal()

>>> tolta modalità stratificata (LGNN):
	- in BaseCGNN.Loop() tolto parametro nodeplus
	- in BaseCGNN.Loop() tolto parametro arcplus
	- in CGNNnodeBased.Loop() tolto parametro nodeplus
	- in CGNNnodeBased.Loop() tolto parametro arcplus
	- in CGNNnodeBased.Loop() tolto "nodes = tf.concat([nodes, nodeplus], axis=1)"
	- in CGNNnodeBased.Loop() tolto "arcs_label = tf.concat([arcs_label, arcplus], axis=1)"
	- in CGNNgraphBased.Loop() tolto parametro nodeplus
	- in CGNNgraphBased.Loop() tolto parametro arcplus
	- in CGNNgraphBased.Loop() tolto passaggio parametri nodeplus e arcplus a super.Loop()

>>> cambiata condizione di convergenza (conta solo il numero di iterazioni):
	- in CGNNnodeBased.__init__() tolto parametro threshold
	- in CGNNnodeBased.__init__() tolta dichiarazione self.state_threshold = threshold
	- in CGNNnodeBased.copy() tolto passaggio parametro threshold al costruttore
	- in CGNNnodeBased.condition() tolto calcolo distance_vector
	- in CGNNnodeBased.condition() tolto calcolo state_norm
	- in CGNNnodeBased.condition() tolto calcolo scaled_state_norm
	- in CGNNnodeBased.condition() tolto controllo tf.greater(outDistance, scaled_state_norm)
	- in CGNNnodeBased.condition() tolta condizione rispetto controllo tf.greater(outDistance, scaled_state_norm) per tutti gli stati
	- in CGNNnodeBased.condition() cambiato return statement return tf.logical_and(c1, c2) -> return tf.less(k, self.max_iteration)
	- in CGNNnodeBased.condition() tolto parametro state
	- in CGNNnodeBased.condition() tolto parametro state_old	

>>> sostituito net_state con lista di reti net_state_list:
	- in CGNNnodeBased.__init__() cambiato net_state: tf.keras.models.Sequential -> net_state_list: list[tf.keras.models.Sequential]
	- in CGNNnodeBased.__init__() cambiato self.net_state = net_state -> self.net_state_list = net_state_list
	- in CGNNnodeBased.copy() adattato netS = tf.keras.models.clone_model(self.net_state) a lista di reti
	- in CGNNnodeBased.copy() adattato netS.set_weights(self.net_state.get_weights()) a lista di reti
	- in CGNNnodeBased.copy() adattato return a lista di reti, cambiando il primo parametro del costruttore chiamato net_state -> net_state_list
	- in CGNNnodeBased.trainable_variables() cambiato primo componente tupla list[list[tf.Tensor]] -> list[list[list[tf.Tensor]]] 
	- in CGNNnodeBased.trainable_variables() adattato return (solo primo componente tupla) a lista di reti
	- in CGNNnodeBased.get_weights() cambiato primo componente tupla list[list[array]] -> list[list[list[array]]]
	- in CGNNnodeBased.get_weights() adattato return (solo primo componente tupla) a lista di reti
	- in CGNNnodeBased.set_weights() cambiato primo componente tupla in input list[list[array]] -> list[list[list[array]]]
	- in CGNNnodeBased.set_weights() diviso assert in due: len(state_weights)==len(self.list_net_state), len(output_weights)==1
	- in CGNNnodeBased.set_weights() adattato self.net_state.set_weights(weights_state[0]) con ciclo for per lista di reti
	- in BaseCGNN.trainable_variables() cambiato primo componente tupla list[list[tf.Tensor]] -> list[list[list[tf.Tensor]]]
	- in BaseCGNN.get_weights() cambiato primo componente tupla list[list[array]] -> list[list[list[array]]]
	- in BaseCGNN.set_weights() adattai argomenti a lista di reti per il calcolo dello stato
	- in BaseCGNN.train() adattata la scrittura dei pesi delle reti per lo stato su Tensorboard in "# TRAINING EVALUATION STEP"
	- in BaseGCNN.train() adattata la scrittura dei pesi delle reti per lo stato su Tensorboard in "# Tensorboard Update FINAL"

>>> aggiunta matrice booleana type_mask (#nodi x #tipi) per selezionare quali nodi appartengono a quali tipi:
	- in CompositeGraphObject.__init__() tolte costruzioni self.DIM_NODE_LABEL, self.DIM_ARC_LABEL, self.DIM_TARGET perchè non più usate
	- in CompositeGraphObject.__init__() aggiunto parametro type_mask
	- in CompositeGraphObject.__init__() aggiunta costruzione di self.type_mask
	- in CompositeGraphObject.__init__() aggiunta self.type_mask.shape[0] al controllo della lunghezza delle maschere
	- in CompositeGraphObject aggiunto metodo CompositeGraphObject.getTypeMask(self)
	- in CompositeGraphObject.copy() aggiunto passaggio parametro type_mask=self.getTypeMask()
	- in CompositeGraphObject.save() aggiunto parametro save_type_mask:bool=True per salvare o meno la type_mask
	- in CompositeGraphObject.save() aggiunto salvataggio type_mask
	- in CompositeGraphObject.merge() aggiunta type_mask alla tupla zip di ogni grafo
	- in CompositeGraphObject.merge() aggiunta concatenazione delle type_mask
	- in CompositeGraphObject.merge() aggiunto passaggio parametro type_mask=typemask a return

>>> modificato calcolo dello stato per tenere in considerazione N tipi di nodo diversi:
	- in CGNNnodeBased.Loop() aggiunta raccolta <type_mask> dal GraphObject
	- in CGNNnodeBased.Loop() aggiunto passaggio parametro <type_mask> a tf.while_loop(self.convergence, self.condition)
	- in CGNNnodeBased.__init__() aggiunto parametro type_label_lengths per tenere traccia lunghezze label dei vari tipi di nodo
	- in CGNNnodeBased.__init__() aggiunta costruzione self.type_label_lengths
	- in CGNNnodeBased.__init__() aggiunta costruzione self.type_offsets basata su self.type_label_lengths
	- in CGNNnodeBased.copy() aggiunto passaggio parametro type_label_lengths = self.type_label_lengths
	- in CGNNnodeBased aggiunta funzione type_loop_condition() per ciclare il calcolo dello stato sui diversi tipi
	- in CGNNnodeBased aggiunta funzione type_loop_body() per ciclare il calcolo dello stato sui diversi tipi
	- in CGNNnodeBased.convergence() cambiata concatenazione inp_state (nodes, state, message) -> (state, message, nodes)
	- in CGNNnodeBased.convergence() aggiunto parametro <type_mask>
	- in CGNNnodeBased.convergence() aggiunta dichiarazione di un vettore <inp_index> per ricostruire <state> dopo il calcolo
	- in CGNNnodeBased.convergence() aggiunta pre-dichiarazione del tensore <out_state> per calcolare il nuovo stato
	- in CGNNnodeBased.convergence() aggiunta pre-dichiarazione del tensore <out_index> per ricostruire il nuovo tensore dello stato
	- in CGNNnodeBased.convergence() sostituita chiamata a state net con tf.while_loop() che chiama tutte le state net
	- in CGNNnodeBased.convergence() aggiunta ricostruzione state tensor dopo chiamate alle state net
	
